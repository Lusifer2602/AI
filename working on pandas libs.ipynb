{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mydataset = {\n",
    "  'cars': [\"BMW\", \"Volvo\", \"Ford\"],\n",
    "  'passings': [3, 7, 2]\n",
    "}\n",
    "\n",
    "myvar = pd.DataFrame(mydataset)\n",
    "\n",
    "print(myvar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "mydata={\n",
    "    'Name':['Pranav', 'Divyam', 'Harsh', 'Akash', 'Pathakji'],\n",
    "    'Age': [18, 22, 21, 21, 23],\n",
    "    'Salary': ['1cr', '10cr', '30cr', '450cr', '35cr']\n",
    "    }\n",
    "\n",
    "data= pandas.DataFrame(mydata)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "newdata= {\n",
    "    'Brand': ['Puma', 'Reebok', 'Adidas', 'Adrenex'],\n",
    "    'Products sold' : [1000, 200, 20000, 12344],\n",
    "}\n",
    "\n",
    "print(pandas.DataFrame(newdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "x=np.array(['p', 'a', 'n', 'd', 'a', 's'])\n",
    "a=pd.Series(x) #since this is a single column table hence we can commence it under series method of pandas\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#  a is a list of strings\n",
    "x=['Python', 'Pandas']\n",
    "df=pd.DataFrame(x)\n",
    "print(df) #Calling Datafarme constructor on list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "cd={'Names':['Ammar Ali', \"Pranav\", 'Arsil', 'Akash', 'Jatin'],\n",
    "       'Marks':[12, 30, -5, 15, 10],\n",
    "       'Grades':['B', 'O', 'A', 'F', 'D']}\n",
    "x=pd.DataFrame(cd)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.head(2) #will print first 2 rows of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.describe()  #gives mean, median, count, %, max.-min. value of the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PANDAS LIB. from geekforgeeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame() #creating an empty DataFrame under pandas lib\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=['Geeks', 'for', 'Geeks',\n",
    "     'portal', 'for', 'Geeks']\n",
    "print(pd.DataFrame(lst)) #this syntax create a DataFrame of the variable unde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data={'Name' : ['Pranav', 'Shubham', 'Tom', 'Cruze', 'Hillary'], 'Age' : [20, 35, 56, 40, 25]}\n",
    "print(pd.DataFrame(data)) #this prints "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ass=pd.DataFrame({\n",
    "    'Name' : ['Pranav', 'Shubham', 'Tom', 'Cruze', 'Hillary'], \n",
    "    'Age' : [20, 35, 56, 40, 25],\n",
    "    'Job' : ['Data scientst', 'Back-end-dev', 'Front-end-dev', 'dev-ops', 'IT']\n",
    "})\n",
    "print(ass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the code above can also be executed as\n",
    "ass={\n",
    "    'Name' : ['Pranav', 'Shubham', 'Tom', 'Cruze', 'Hillary'], \n",
    "    'Age' : [20, 35, 56, 40, 25],\n",
    "    'Job' : ['Data scientst', 'Back-end-dev', 'Front-end-dev', 'dev-ops', 'IT']\n",
    "}\n",
    "df=pd.DataFrame(ass)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas can perform a variable types of functions over dataset's columns/rows\n",
    "\n",
    "it can give answers like -\n",
    "-relation b/w two or more columns\n",
    "-avg value\n",
    "-min value\n",
    "-max value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels (If nothing else is specified, the values are labeled with their index number. First value has index 0, and so on...)\n",
    "import pandas as pd\n",
    "a=['batman', 'superman', 'spiderman', 'kevin levrone']\n",
    "print(a[2]) #spiderman here is on index 3 hence it was printed when a was indexed with label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating labels - yes, its possible to name our own labels\n",
    "import pandas as pd\n",
    "a=[12, 24, 36, 48, 60, 72]\n",
    "new=pd.Series(a, index=['Twleve ones are', 'Twelve twos are', 'Twelve threes are', 'Twelve fours are', 'Twelve fives are', 'Twelve sixz are'] )\n",
    "print(new)\n",
    "\n",
    "# on creating labels its also possible to access these values using their label\n",
    "# for eg\n",
    "print('value for 4th position (if first is taken 0) will be : ', new['Twelve fives are'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using key:value pairs for DataFrame\n",
    "import pandas as pd\n",
    "a={'one':'Spiderman', 2:'Goblin', 'three':'Lizard', 4:'bhadak krdi bc'}\n",
    "print(pd.Series(a))\n",
    "print()\n",
    "# to note : keys of the dictionaries become the labels when printed with Series method of pandas\n",
    "diet={'day 1' : '320 calories', 'day 2':'5000 calories', 'day 3':'1000000 calories'}\n",
    "print(pd.Series(diet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''to print only a desired index value'''\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "calories = {\"day1\": 420, \"day2\": 380, \"day3\": 390}\n",
    "\n",
    "myvar = pd.Series(calories, index = [\"day1\", \"day3\"])\n",
    "\n",
    "print(myvar) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATAFRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''a dataframe is a 2 dimensional data structure with rows and columns''' #note that Series previously was one dimensional only, i.e. for a column\n",
    "data={\n",
    "    \"Names\":['Clark Kent', 'Bruce Wayne', 'Barry Allen', 'Wade Willson'],\n",
    "    \"Hero Name\":['Superman', 'Batman', 'Flash', 'Deadpool']\n",
    "}\n",
    "df=pd.DataFrame(data) #this command loads data into DataFrame method to print it tabularly as rows n columns\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locate Row\n",
    "'''its possible to locate a row by giving its index value under the loc method by applying this method to the DataFrame's variable'''\n",
    "# note that first the Dataset has to be saved in a pandas DataFrame under some variable\n",
    "print('''\n",
    "      test 1\n",
    "      ''')\n",
    "print(df.loc[1])\n",
    "# to get more than one we can just add another index value, for eg:\n",
    "print('''\n",
    "      test 2''')\n",
    "print(df.loc[[0,2]])\n",
    "print('''\n",
    "      test 3''')\n",
    "print(df.loc[[0,3,1,1]]) #when using [] result is a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WORKING WITH CSV FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset=pd.read_csv(\"Marvel Movies.csv\")\n",
    "print(dataset.to_string()) #this will print the entire dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if there's a larger dataframe and it is printed without to_string() then output will be a summarised view of the dataset\n",
    "ABBA=pd.read_csv(\"Marvel Movies.csv\")\n",
    "print(ABBA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max rows - The number of rows returned is defined in Pandas option settings.\n",
    "# You can check your system's maximum rows with the pd.options.display.max_rows statement.\n",
    "\n",
    "print(\"maximum rows in this dataset are :\", pd.options.display.max_rows)\n",
    "print(\"maximum columns in the same dataset are :\", pd.options.display.max_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WORKING WITH JSON FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "'''python dictionaries = json hence both can be printed into a DataFrame very easily'''\n",
    "\n",
    "data = {\n",
    "  \"Duration\":{\n",
    "    \"0\":60,\n",
    "    \"1\":60,\n",
    "    \"2\":60,\n",
    "    \"3\":45,\n",
    "    \"4\":45,\n",
    "    \"5\":60\n",
    "  },\n",
    "  \"Pulse\":{\n",
    "    \"0\":110,\n",
    "    \"1\":117,\n",
    "    \"2\":103,\n",
    "    \"3\":109,\n",
    "    \"4\":117,\n",
    "    \"5\":102\n",
    "  },\n",
    "  \"Maxpulse\":{\n",
    "    \"0\":130,\n",
    "    \"1\":145,\n",
    "    \"2\":135,\n",
    "    \"3\":175,\n",
    "    \"4\":148,\n",
    "    \"5\":127\n",
    "  },\n",
    "  \"Calories\":{\n",
    "    \"0\":409,\n",
    "    \"1\":479,\n",
    "    \"2\":340,\n",
    "    \"3\":282,\n",
    "    \"4\":406,\n",
    "    \"5\":300\n",
    "  }\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALYSING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first step is viewing the data using head() method\n",
    "'''head method by default returns first 5 rows as output'''\n",
    "import pandas as pd\n",
    "df=pd.read_csv(\"Marvel Movies.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tail() method\n",
    "print(df.tail()) #will print last 5 data off the DataFrameb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#will return information about the DataFrame\n",
    "print(df.info())\n",
    "# The info() method also tells us how many Non-Null values there are present in each column, and in our data set it seems like there are 36 Non-Null values in the \"year\" column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEANING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''cleaning data cells means to remove or get rid of bad cells\n",
    "bas cells can include empty cells, data in wrong format, wrong data, Duplicates'''\n",
    "a=\"cleaning data sets begins here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "'''the lonan_data_1.csv file has multiple empty cells in the csv and in order to remove the rows with such data we use .dropna() method '''\n",
    "df=pd.read_csv(\"loan_dafta_1.csv\").dropna()\n",
    "print(df.to_string()) #somehow this command also removed null-celled and saved the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the above syntax doesn't save the file as edited\n",
    "'''in order to permanently save the file as edited(i.e. null celled rows rmoved, one can (inplace=True))'''\n",
    "so=pd.read_csv(\"loan_data_1.csv\")\n",
    "print(so.dropna(inplace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=pd.read_csv(\"loan_data_1 - Copy.csv\")\n",
    "print(name.to_string()) #this is a file that hasn't been cleaned and is the exact replica of the loans_data1.csv file before getting cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''didn't find a csv file to experiment on this so leacing the syntax here'''\n",
    "import pandas as pd\n",
    "'''\n",
    "--> Replace NULL values with the number 130:\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "df.fillna(130, inplace = True)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Replace NULL values in the \"Calories\" columns with the number 130:\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "df[\"Calories\"].fillna(130, inplace = True)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing values of a column using mean, median, mode\n",
    "'''incase the demand is to fill the empty cells with mean or medain or  mode of rest of the data'''\n",
    "###\n",
    "'''for replacing with mean\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "x = df[\"Calories\"].mean()\n",
    "\n",
    "df[\"Calories\"].fillna(x, inplace = True)'''\n",
    "\n",
    "#\n",
    "\n",
    "'''for replacing with median\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "x = df[\"Calories\"].median()\n",
    "df[\"Calories\"].fillna(x, inplace = True)\n",
    "'''\n",
    "#\n",
    "\n",
    "'''for replacing wit mode\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "x = df[\"Calories\"].mode()[0]\n",
    "df[\"Calories\"].fillna(x, inplace = True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEANING OF WRONG FORMAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "print(pd.read_csv(\"Marvel Movies.csv\").dropna(inplace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "'''\n",
    "In our Data Frame, we have two cells with the wrong format. Check out row 22 and 26, the 'Date' column should be a string that represents a date:\n",
    "\n",
    "Let's try to convert all cells in the 'Date' column into dates.\n",
    "# the dataset in the tutorial has a file with a wrongly written date cell and a cell with no date at all\n",
    "**in order to rectify the date using pandas following syntax has been used**\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "print(df.to_string()) '''\n",
    "\n",
    "\n",
    "a='iambatman'\n",
    "# and now to remove the row with no date mentioned,\n",
    "# follow this syntax\n",
    "# df.dropna(subset=['Date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make copy of a file \n",
    "\n",
    "import pandas as pd\n",
    "a={\n",
    "    \"name\":[\"Batman\", \"Superman\", \"Spiderman\", \"Kratos\", \"IronMan\", \"Hawkeye\", \"Falcon\"],\n",
    "    \"kills\":[10, 200, 1, 20000, 2000000, 210, 12 ],\n",
    "}\n",
    "df=pd.DataFrame(a).copy(deep=True)\n",
    "\n",
    "'''\tOptional. Default True. Specifies whether to make a deep or a shallow copy.\n",
    "By default (deep=True, any changes made in the original DataFrame will NOT be reflected in the copy.\n",
    "\n",
    "With the parameter deep=False, it is only the reference to the data (and index) that will be copied, and any changes made in the original will be reflected in the copy, and, any changes made in the copy will be reflected in the original.'''\n",
    "# now we work on this dataframe without affecting the original one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# back to cleaning data\n",
    "import pandas as pd\n",
    "df=pd.read_csv(\"Marvel Movies.csv\").copy() #default value for deep under copy method is true so changes to this file won't be affecting the original file\n",
    "print(df.to_string())\n",
    "# now to change a data's value in this dataframe we'll use the following code\n",
    "df.loc[14, 'movie']='Eternals (bekar movie)'\n",
    "print('''\n",
    "\n",
    "''')\n",
    "print(df.to_string())\n",
    "\n",
    "# here we can clearly see how the loc method applied to the csv file changed the desired cell's value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''looping through the whole column to apply a criteria to the whole dataset'''\n",
    "import pandas as pd \n",
    "\n",
    "df=pd.read_csv(\"Marvel Movies.csv\").copy(deep=True) #default value for deep under copy method is true so changes to this file won't be affecting the original file\n",
    "for i in df.index:\n",
    "    if df.loc[i, 'worldwide gross ($m)']>1000:\n",
    "        df.loc[i, 'worldwide gross ($m)']=1000\n",
    "# now here every movie greater than the earning of $1000M has been its worldwide gross rounded off down to 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# used blackbox ai here to understand some concepts\n",
    "\n",
    "a={\n",
    "    \"name\":[\"Batman\", \"Superman\", \"Spiderman\", \"Kratos\", \"IronMan\", \"Hawkeye\", \"Falcon\"],\n",
    "    \"kills\":[10, 200, 1, 20000, 2000000, 210, 12 ],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(a)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['name'] == 'Superman':\n",
    "        df.loc[index, 'name'] = 'Hulk'\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing rows from a dataset\n",
    "df=pd.read_csv(\"Marvel Movies.csv\").copy(deep=True) #default value for deep under copy method is true so changes to this file won't be affecting the original file\n",
    "'''looping through the whole column to apply a criteria to the whole dataset'''\n",
    "import pandas as pd \n",
    "\n",
    "df=pd.read_csv(\"Marvel Movies.csv\").copy(deep=True) #default value for deep under copy method is true so changes to this file won't be affecting the original file\n",
    "for i in df.index:\n",
    "    if df.loc[i, 'worldwide gross ($m)']>1000:\n",
    "        df.drop(i, inplace=True) #'''this removes all the rows that have globally made more than 100m$ in their release year'''\n",
    "print(df.to_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DISCOVERING & REMOVING DUPLICATES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''looping through the whole column to apply a criteria to the whole dataset'''\n",
    "import pandas as pd \n",
    "\n",
    "df=pd.read_csv(\"loan_data_1 - Copy.csv\")\n",
    "\n",
    "print(df.duplicated())#this tells if there are any duplicate values in the dataset\n",
    "\n",
    "'''to remove duplicates'''\n",
    "df.drop_duplicates(inplace=True) #inplace ensures the changed data is saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding relationships in the dataset\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(\"data.csv\").copy(deep=True)\n",
    "df.corr()\n",
    "'''\n",
    "Result Explained\n",
    "The Result of the corr() method is a table with a lot of numbers that represents how well the relationship is between two columns.\n",
    "\n",
    "The number varies from -1 to 1.\n",
    "\n",
    "1 means that there is a 1 to 1 relationship (a perfect correlation), and for this data set, each time a value went up in the first column, the other one went up as well.\n",
    "\n",
    "0.9 is also a good relationship, and if you increase one value, the other will probably increase as well.\n",
    "\n",
    "-0.9 would be just as good relationship as 0.9, but if you increase one value, the other will probably go down.\n",
    "\n",
    "0.2 means NOT a good relationship, meaning that if one value goes up does not mean that the other will.\n",
    "\n",
    "What is a good correlation? It depends on the use, but I think it is safe to say you have to have at least 0.6 (or -0.6) to call it a good correlation.\n",
    "\n",
    "Perfect Correlation:\n",
    "We can see that \"Duration\" and \"Duration\" got the number 1.000000, which makes sense, each column always has a perfect relationship with itself.\n",
    "\n",
    "Good Correlation:\n",
    "\"Duration\" and \"Calories\" got a 0.922721 correlation, which is a very good correlation, and we can predict that the longer you work out, the more calories you burn, and the other way around: if you burned a lot of calories, you probably had a long work out.\n",
    "\n",
    "Bad Correlation:\n",
    "\"Duration\" and \"Maxpulse\" got a 0.009403 correlation, which is a very bad correlation, meaning that we can not predict the max pulse by just looking at the duration of the work out, and vice versa.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PANDAS PLOTTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "df=pd.read_csv(\"data.csv\").copy(deep=True)\n",
    "df.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for scattered plot of the above graph\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "df=pd.read_csv(\"data.csv\").copy(deep=True)\n",
    "\n",
    "\n",
    "df.plot(kind = 'scatter', x = 'Duration', y = 'Calories')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('data.csv').copy()\n",
    "\n",
    "df.plot(kind = 'scatter', x = 'Duration', y = 'Maxpulse')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
